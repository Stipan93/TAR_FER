# TAR_FER
Text analysis and retrieval project, Spring 2017


# Task description

3 Semantic Textual Similarity
Semantic textual similarity (STS) measures how similar two text snippets are. The task is, given two sentences, to determine their similarity score on a continuous scale from 0 to 5. The score of 5 denotes a perfect semantic equivalence. This task was offered in multiple tracks, covering various cross-lingual and monolingual pairs. Your task, however, is the track concerned with English monolingual pairs. Of course, you are encouraged to give a shot on other tracks as well.

* [Competition website](http://alt.qcri.org/semeval2017/task1/)
* [Dataset](http://alt.qcri.org/semeval2017/task1/index.php?id=data-and-tools)


Entry points:

* Agirre, Eneko, et al. SemEval-2016 task 1: Semantic textual similarity, monolingual [link](http://www.aclweb.org/anthology/S16-1081)
and cross-lingual evaluation.
* BrychcÄ±n, Tomas, and Lukas Svoboda. Semantic textual similarity using lexical, syntactic, and semantic information. [link](https://pdfs.semanticscholar.org/9a75/ef477b09fb868ee80c76602efa9e03696a67.pdf)
* Saric, Frane, et al. Takelab: Systems for measuring semantic text similarity [link](http://www.aclweb.org/anthology/S12-1060)

# Folder layout
## src
Source files
## paper
Paper source files
## model
Place to save models
## refs
Place to save references, mostly local only
## log
Place to save logs, mostly local only

# Important files

* /Dockerfile -- Dockerfile for src running setting
